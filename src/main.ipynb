{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53063dd7",
   "metadata": {},
   "source": [
    "# Aluno: Lucas Felipe de Souza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652369e",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "71a5294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f6950",
   "metadata": {},
   "source": [
    "# Ler CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8c9c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCsv(file):\n",
    "    \"\"\"\n",
    "    L√™ um arquivo CSV e retorna um DataFrame do pandas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Lendo o arquivo: {file}\")\n",
    "        # Verifica se o arquivo existe e √© um CSV\n",
    "        if not file.endswith('.csv'):\n",
    "            raise ValueError(\"O arquivo n√£o √© um CSV v√°lido.\")\n",
    "        # L√™ o arquivo CSV\n",
    "        df = pd.read_csv(file)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99185b8",
   "metadata": {},
   "source": [
    "# Remover espa√ßos em brancos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "953c1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_whitespace(df):\n",
    "    \"\"\"\n",
    "    Remove espa√ßos em branco no in√≠cio e no final de todas as strings no DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Aplica o strip em cada valor de string em cada coluna\n",
    "        return df.apply(lambda col: col.map(lambda x: x.strip() if isinstance(x, str) else x) if col.dtype == 'object' else col)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao limpar espa√ßos em branco: {e}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd255b4",
   "metadata": {},
   "source": [
    "# Normaliza a coluna status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4e5c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_status(df):\n",
    "    \"\"\"\n",
    "    Normaliza a coluna 'status' para padronizar as express√µes de status.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com a coluna 'status' normalizada.\n",
    "    \"\"\"\n",
    "    # Dicion√°rio de mapeamento para normalizar os status\n",
    "    status_map = {\n",
    "        'Pagamento Confirmado': 'Pagamento Confirmado',\n",
    "        'Pgto Confirmado': 'Pagamento Confirmado',\n",
    "        'PC': 'Pagamento Confirmado',\n",
    "        'Pago': 'Pagamento Confirmado',\n",
    "        'Entregue': 'Entregue',\n",
    "        'Entg': 'Entregue',\n",
    "        'Entregue com Sucesso': 'Entregue',\n",
    "        'Em Separa√ß√£o': 'Em Separa√ß√£o',\n",
    "        'Sep': 'Em Separa√ß√£o',\n",
    "        'Separando': 'Em Separa√ß√£o',\n",
    "        'Aguardando Pagamento': 'Aguardando Pagamento',\n",
    "        'Aguardando Pgto': 'Aguardando Pagamento',\n",
    "        'aguardando pagamento': 'Aguardando Pagamento',\n",
    "        'AP': 'Aguardando Pagamento',\n",
    "        'Em Transporte': 'Em Transporte',\n",
    "        'Transp': 'Em Transporte',\n",
    "        'Transportando': 'Em Transporte',\n",
    "    }\n",
    "\n",
    "    # Aplicar o mapeamento para normalizar os valores da coluna 'status'\n",
    "    df['status'] = df['status'].str.strip().map(status_map).fillna(df['status'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28c410",
   "metadata": {},
   "source": [
    "# Remove caracteres especiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9b32407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(df, columns):\n",
    "    \"\"\"\n",
    "    Remove caracteres especiais de colunas espec√≠ficas em um DataFrame.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "    columns (list): Lista de colunas onde os caracteres especiais ser√£o removidos.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com os caracteres especiais removidos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for column in columns:\n",
    "            df[column] = df[column].apply(\n",
    "                lambda x: re.sub(r'[^\\w\\s]', '', x) if isinstance(x, str) else x\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao remover caracteres especiais: {e}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d22ae0",
   "metadata": {},
   "source": [
    "# Normaliza os nomes dos produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_and_normalize_products(df, column='produto', threshold=60):\n",
    "    \"\"\"\n",
    "    Compara e normaliza os nomes dos produtos em um DataFrame.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "    column (str): O nome da coluna de produtos a ser normalizada.\n",
    "    threshold (int): O limiar de similaridade para agrupar produtos.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com os nomes dos produtos normalizados.\n",
    "    \"\"\"     \n",
    "    unique_products = df[column].dropna().unique()\n",
    "    product_mapping = {}\n",
    "\n",
    "    for product in unique_products:\n",
    "        if product in product_mapping:\n",
    "            continue\n",
    "        similar_products = [other for other in unique_products if fuzz.ratio(product, other) >= threshold]\n",
    "        most_frequent_product = df[df[column].isin(similar_products)][column].mode()[0]\n",
    "        \n",
    "        for similar in similar_products:\n",
    "            product_mapping[similar] = most_frequent_product\n",
    "\n",
    "    df[column] = df[column].map(product_mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0fe5b0",
   "metadata": {},
   "source": [
    "# Normaliza os valores monet√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a5f5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_monetary_values(df, column):\n",
    "    \"\"\"\n",
    "    Normaliza os valores monet√°rios em uma coluna espec√≠fica de um DataFrame.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "    column (str): O nome da coluna a ser normalizada.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com a coluna normalizada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove espa√ßos em branco e outros caracteres n√£o num√©ricos, exceto v√≠rgula ou ponto\n",
    "        df[column] = df[column].str.replace(r\"[^\\d,\\.]\", \"\", regex=True)\n",
    "\n",
    "        # Substitui a v√≠rgula por ponto para garantir que os valores possam ser convertidos corretamente\n",
    "        df[column] = df[column].str.replace(\",\", \".\", regex=False)\n",
    "\n",
    "        # Converte os valores para num√©rico, substituindo erros por NaN\n",
    "        df[column] = pd.to_numeric(df[column], errors=\"coerce\")\n",
    "\n",
    "        # Arredonda os valores para duas casas decimais\n",
    "        df[column] = df[column].round(2)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao normalizar valores monet√°rios na coluna '{column}': {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ed4dc",
   "metadata": {},
   "source": [
    "# Corrige a capitaliza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "830415b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text_capitalization(df):\n",
    "    \"\"\"\n",
    "    Corrige a capitaliza√ß√£o dos campos de texto em um DataFrame.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com os campos de texto corrigidos.\n",
    "    \"\"\"\n",
    "    campos_texto = ['cliente', 'produto', 'status', 'cidade', 'pais', 'pagamento', 'vendedor', 'marca']\n",
    "    for coluna in campos_texto:\n",
    "        df[coluna] = df[coluna].str.title().str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db47872",
   "metadata": {},
   "source": [
    "# Preenche valores ausentes na coluna 'vendedor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8d0f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_vendedor(df):\n",
    "    \"\"\"\n",
    "    Preenche valores ausentes na coluna 'vendedor' com a moda por 'id_da_compra'.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com a coluna 'vendedor' preenchida.\n",
    "    \"\"\"\n",
    "    df['vendedor'] = df.groupby('id_da_compra')['vendedor'].transform(\n",
    "        lambda x: x.mode().iloc[0] if not x.mode().empty else x\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4b37b",
   "metadata": {},
   "source": [
    "# Limpa e padroniza a coluna de valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce57a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_price_data(df):\n",
    "    \"\"\"\n",
    "    Limpa e padroniza a coluna de valor:\n",
    "    - Converte para n√∫mero.\n",
    "    - Preenche valores nulos com a mediana por produto + marca.\n",
    "    - Remove outliers por produto + marca.\n",
    "    - Arredonda os valores para duas casas decimais.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): DataFrame com colunas 'produto', 'marca' e 'preco'.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame com valores corrigidos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Converte a coluna de pre√ßo para float, for√ßando erros para NaN\n",
    "    df['valor'] = pd.to_numeric(df['valor'], errors='coerce')\n",
    "\n",
    "    # 2. Preenche valores nulos com a mediana por produto + marca\n",
    "    df['valor'] = df.groupby(['produto', 'marca'])['valor'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "    # 3. Remove outliers dentro de cada grupo (produto + marca)\n",
    "    def remove_outliers(group):\n",
    "        Q1 = group['valor'].quantile(0.25)\n",
    "        Q3 = group['valor'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        return group[(group['valor'] >= lower) & (group['valor'] <= upper)]\n",
    "\n",
    "    df = df.groupby(['produto', 'marca'], group_keys=False).apply(remove_outliers)\n",
    "\n",
    "    # 4. Arredonda os pre√ßos\n",
    "    df['valor'] = df['valor'].round(2)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45deb70",
   "metadata": {},
   "source": [
    "# Preenche valores ausentes em colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f852831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, columns):\n",
    "    \"\"\"\n",
    "    Preenche valores ausentes em colunas espec√≠ficas de um DataFrame usando a m√©dia e a mediana.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "    columns (list): Lista de colunas para preencher valores ausentes.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com os valores ausentes preenchidos.\n",
    "    \"\"\"\n",
    "    def calculate_mean_median(column):\n",
    "        return df[column].agg(['mean', 'median']).mean()\n",
    "\n",
    "    try:\n",
    "        for column in columns:\n",
    "            df[column] = df[column].fillna(calculate_mean_median(column))\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao preencher valores ausentes: {e}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efde65b3",
   "metadata": {},
   "source": [
    "# Convertendo para valores num√©ricos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7b4647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numeric_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Normaliza colunas num√©ricas, convertendo para valores num√©ricos.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "    columns (list): Lista de colunas a serem normalizadas.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com as colunas normalizadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for column in columns:\n",
    "            df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao normalizar colunas num√©ricas: {e}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226272c3",
   "metadata": {},
   "source": [
    "# Normaliza as colunas de data e hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "714d3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_datetime_columns(df):\n",
    "    \"\"\"\n",
    "    Normaliza as colunas de data e hora em um DataFrame.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo as colunas 'data' e 'hora'.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com as colunas 'data' e 'hora' normalizadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df['data'] = pd.to_datetime(df['data'], errors='coerce')  # erros viram NaT\n",
    "        df['hora'] = pd.to_datetime(df['hora'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao normalizar colunas de data/hora: {e}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160fcd41",
   "metadata": {},
   "source": [
    "# Corrige os CEPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "74fc3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_cep_format(df):\n",
    "    \"\"\"\n",
    "    Corrige os CEPs para manter o padr√£o com h√≠fen.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo a coluna 'cep'.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com os CEPs corrigidos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df['cep'] = df['cep'].str.replace(r'\\D', '', regex=True).str.zfill(8)\n",
    "        df['cep'] = df['cep'].str[:5] + '-' + df['cep'].str[5:]\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao corrigir o formato dos CEPs: {e}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9eff0",
   "metadata": {},
   "source": [
    "# Corrige tipo das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a7d0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_column_formats(df):\n",
    "\t\"\"\"\n",
    "\tCorrige os formatos das colunas no DataFrame.\n",
    "\t\n",
    "\tPar√¢metros:\n",
    "\tdf (pd.DataFrame): O DataFrame contendo os dados.\n",
    "\t\n",
    "\tRetorna:\n",
    "\tpd.DataFrame: O DataFrame com os formatos corrigidos.\n",
    "\t\"\"\"\n",
    "\ttry:\n",
    "\t\t# Garantir que colunas num√©ricas estejam no formato correto\n",
    "\t\tnumeric_columns = ['valor', 'quantidade', 'total', 'frete']\n",
    "\t\tfor column in numeric_columns:\n",
    "\t\t\tdf[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "\t\t# Garantir que colunas de texto estejam no formato string e remover espa√ßos\n",
    "\t\ttext_columns = ['status', 'cep', 'pagamento']\n",
    "\t\tfor column in text_columns:\n",
    "\t\t\tdf[column] = df[column].astype(str).str.strip()\n",
    "\n",
    "\t\t# Garantir que colunas como 'produto', 'marca', 'vendedor', 'cliente', 'pais', 'cidade', 'estado' sejam categ√≥ricas\n",
    "\t\tcategorical_columns = ['produto', 'marca', 'vendedor', 'cliente', 'pais', 'cidade', 'estado']\n",
    "\t\tfor column in categorical_columns:\n",
    "\t\t\tdf[column] = df[column].astype('category')\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Erro ao corrigir os formatos das colunas: {e}\")\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f15dae",
   "metadata": {},
   "source": [
    "#  Calcula o valor total do pedido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b3222c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total(df):\n",
    "    \"\"\"\n",
    "    Calcula o total como valor * quantidade + frete, \n",
    "    verificando se as colunas 'valor' e 'quantidade' est√£o definidas.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com a coluna 'total' atualizada.\n",
    "    \"\"\"\n",
    "    if 'valor' in df.columns and 'quantidade' in df.columns:\n",
    "        df['total'] = df['valor'] * df['quantidade'] + df['frete']\n",
    "        # Arredondar a coluna 'total' para 2 casas decimais\n",
    "        df['total'] = df['total'].round(2)\n",
    "    else:\n",
    "        print(\"As colunas 'valor' e/ou 'quantidade' n√£o est√£o definidas no DataFrame.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc22da",
   "metadata": {},
   "source": [
    "# Preenche o valor do frete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d0adb012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_frete_by_cep(df, moda_cep):\n",
    "    \"\"\"\n",
    "    Preenche os valores de frete ausentes com base no CEP.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "    moda_cep (pd.Series): S√©rie com os valores de CEP e frete mais comuns.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com os valores de frete preenchidos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df['frete'] = df.apply(\n",
    "            lambda row: moda_cep.get(row['cidade'], row['frete']) if pd.isnull(row['frete']) else row['frete'], axis=1\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao preencher o frete: {e}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d09e5",
   "metadata": {},
   "source": [
    "# Trata os dados ind√≠sponiveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bfb3504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"\"\"\n",
    "    Trata os dados faltantes no DataFrame, removendo ou preenchendo conforme necess√°rio.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com dados faltantes tratados.\n",
    "    \"\"\"\n",
    "    # Remover linhas com dados faltantes em colunas cr√≠ticas\n",
    "    df = df.dropna(subset=['valor', 'quantidade', 'total'])\n",
    "\n",
    "    # Preencher dados faltantes com valores padr√£o em outras colunas\n",
    "    df['frete'] = df['frete'].fillna(0)  # Exemplo: preencher com 0\n",
    "    df['status'] = df['status'].fillna('Desconhecido')  # Exemplo: preencher com valor padr√£o\n",
    "    df['cep'] = df['cep'].fillna('00000-000')  # Exemplo: preencher com um CEP padr√£o\n",
    "    df['pagamento'] = df['pagamento'].fillna('N√£o Especificado')  # Exemplo\n",
    "\n",
    "    return df\n",
    "\n",
    "def handle_inconsistent_values(df):\n",
    "    \"\"\"\n",
    "    Trata valores inconsistentes nas colunas do DataFrame.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame contendo os dados.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame com valores inconsistentes tratados.\n",
    "    \"\"\"\n",
    "    # Corrigir valores inconsistentes em colunas num√©ricas\n",
    "    df['valor'] = df['valor'].apply(lambda x: max(x, 0)) \n",
    "    df['quantidade'] = df['quantidade'].apply(lambda x: max(x, 0)) \n",
    "    df['frete'] = df['frete'].apply(lambda x: max(x, 0))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5239e6ae",
   "metadata": {},
   "source": [
    "# Corrige as marcas de acordo com o produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49f14e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_product_brand_discrepancies(df):\n",
    "    \"\"\"\n",
    "    Corrige inconsist√™ncias entre 'produto' e 'marca' com base na moda da marca para cada produto.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): DataFrame com as colunas 'produto' e 'marca'.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame com inconsist√™ncias corrigidas.\n",
    "    \"\"\"\n",
    "    # C√≥pia para n√£o modificar o original diretamente\n",
    "    df_corrigido = df.copy()\n",
    "\n",
    "    # Remove linhas com 'produto' ou 'marca' nulos para o agrupamento\n",
    "    df_validos = df_corrigido.dropna(subset=['produto', 'marca'])\n",
    "\n",
    "    # Calcula a moda (marca mais comum) para cada produto\n",
    "    marca_mais_comum = df_validos.groupby('produto')['marca'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else \"Desconhecido\")\n",
    "\n",
    "    # Cria uma coluna com a marca esperada\n",
    "    df_corrigido['marca_esperada'] = df_corrigido['produto'].map(marca_mais_comum)\n",
    "\n",
    "    # Substitui a marca incorreta pela marca esperada (se for diferente e ambos n√£o forem nulos)\n",
    "    df_corrigido.loc[\n",
    "        df_corrigido['marca'].notna() &\n",
    "        df_corrigido['marca_esperada'].notna() &\n",
    "        (df_corrigido['marca'] != df_corrigido['marca_esperada']),\n",
    "        'marca'\n",
    "    ] = df_corrigido['marca_esperada']\n",
    "\n",
    "    # Remove a coluna auxiliar\n",
    "    df_corrigido.drop(columns=['marca_esperada'], inplace=True)\n",
    "\n",
    "    return df_corrigido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1f22c",
   "metadata": {},
   "source": [
    "# Salva o dataframe em CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d32956a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_dataframe(df, file_path):\n",
    "    \"\"\"\n",
    "    Salva o DataFrame limpo em um arquivo CSV.\n",
    "\n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): O DataFrame a ser salvo.\n",
    "    file_path (str): O caminho do arquivo onde o DataFrame ser√° salvo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"DataFrame salvo com sucesso em {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ad6ef",
   "metadata": {},
   "source": [
    "# Gera um relat√≥rio de mudan√ßas entre dois DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b4c90fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe_change_report(df_before, df_after, primary_key='id_da_compra'):\n",
    "\t\"\"\"\n",
    "\tGera um relat√≥rio completo das altera√ß√µes entre dois DataFrames.\n",
    "\t\n",
    "\tPar√¢metros:\n",
    "\t- df_before: DataFrame original (antes das altera√ß√µes)\n",
    "\t- df_after: DataFrame modificado (ap√≥s altera√ß√µes)\n",
    "\t- primary_key: Nome da coluna chave para compara√ß√£o (padr√£o: 'id_da_compra')\n",
    "\t\n",
    "\tRetorna:\n",
    "\t- String formatada em Markdown com o relat√≥rio completo\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef format_section(title, content):\n",
    "\t\treturn f\"### {title}\\n{content}\\n\"\n",
    "\n",
    "\tdef format_table(headers, rows):\n",
    "\t\theader_row = \"| \" + \" | \".join(headers) + \" |\\n\"\n",
    "\t\tseparator_row = \"| \" + \" | \".join([\"-\" * len(h) for h in headers]) + \" |\\n\"\n",
    "\t\tdata_rows = \"\\n\".join(\"| \" + \" | \".join(map(str, row)) + \" |\" for row in rows)\n",
    "\t\treturn header_row + separator_row + data_rows\n",
    "\n",
    "\t# Cabe√ßalho do relat√≥rio\n",
    "\treport = f\"# Relat√≥rio de Altera√ß√µes nos Dados\\n**Data de gera√ß√£o:** {datetime.now().strftime('%d/%m/%Y %H:%M')}\\n\\n\"\n",
    "\n",
    "\treport += format_section(\"üìä Estat√≠sticas B√°sicas\", f\"- Registros antes: {len(df_before)}\\n- Registros depois: {len(df_after)}\")\n",
    "\n",
    "\t# 2. Compara√ß√£o de registros\n",
    "\tif primary_key in df_before.columns and primary_key in df_after.columns:\n",
    "\t\tadded = set(df_after[primary_key]) - set(df_before[primary_key])\n",
    "\t\tremoved = set(df_before[primary_key]) - set(df_after[primary_key])\n",
    "\n",
    "\t\tcontent = f\"- Registros adicionados: {len(added)}\\n- Registros removidos: {len(removed)}\"\n",
    "\t\tif removed:\n",
    "\t\t\tcontent += \"\\n\\n#### üóëÔ∏è IDs Removidos\\n```\\n\"\n",
    "\t\t\tcontent += \"\\n\".join(map(str, list(removed)[:10])) # Mostra at√© 10 IDs\n",
    "\t\t\tif len(removed) > 10:\n",
    "\t\t\t\tcontent += f\"\\n... e mais {len(removed) - 10} registros\\n\"\n",
    "\t\t\tcontent += \"\\n```\"\n",
    "\t\treport += format_section(\"üìù Mudan√ßas nos Registros\", content)\n",
    "\n",
    "\n",
    "\treport += format_section(\"‚úèÔ∏è Altera√ß√µes nos Valores\", \"\")\n",
    "\n",
    "\tnulls_before = df_before.isnull().sum()\n",
    "\tnulls_after = df_after.isnull().sum()\n",
    "\tnull_changes = (nulls_before - nulls_after).sort_values(ascending=False)\n",
    "\tnull_changes = null_changes[null_changes != 0]\n",
    "\n",
    "\tif not null_changes.empty:\n",
    "\t\trows = [(col, count) for col, count in null_changes.items()]\n",
    "\t\treport += format_section(\"üîÑ Mudan√ßas em Valores Nulos\", format_table([\"Coluna\", \"Nulos removidos\"], rows))\n",
    "\telse:\n",
    "\t\treport += \"- Nenhuma mudan√ßa significativa em valores nulos\\n\"\n",
    "\n",
    "\tif 'status' in df_before.columns and 'status' in df_after.columns and primary_key in df_before.columns and primary_key in df_after.columns:\n",
    "\t\tstatus_comparison = pd.merge(\n",
    "\t\t\tdf_before[[primary_key, 'status']].rename(columns={'status': 'status_antes'}),\n",
    "\t\t\tdf_after[[primary_key, 'status']].rename(columns={'status': 'status_depois'}),\n",
    "\t\t\ton=primary_key\n",
    "\t\t)\n",
    "\t\tchanged_status = status_comparison[status_comparison['status_antes'] != status_comparison['status_depois']]\n",
    "\n",
    "\t\tif not changed_status.empty:\n",
    "\t\t\tchange_summary = changed_status.groupby(['status_antes', 'status_depois']).size().reset_index(name='quantidade')\n",
    "\t\t\tchange_summary = change_summary.sort_values('quantidade', ascending=False)\n",
    "\t\t\trows = change_summary.values.tolist()\n",
    "\t\t\treport += format_section(\"üîÑ Transforma√ß√µes na Coluna 'status'\", format_table([\"Status Anterior\", \"Status Atual\", \"Registros\"], rows))\n",
    "\t\telse:\n",
    "\t\t\treport += \"- ‚úÖ Nenhuma altera√ß√£o nos valores da coluna 'status' encontrada\\n\"\n",
    "\n",
    "\treport += format_section(\"‚ö†Ô∏è Poss√≠veis Inconsist√™ncias\", \"\")\n",
    "\n",
    "\tif 'produto' in df_after.columns and 'marca' in df_after.columns:\n",
    "\t\tmarca_por_produto = df_after.groupby('produto')['marca'].agg(pd.Series.mode)\n",
    "\t\tinconsistentes = df_after[~df_after.apply(\n",
    "\t\t\tlambda x: x['marca'] in marca_por_produto[x['produto']], axis=1)]\n",
    "\n",
    "\t\tif not inconsistentes.empty:\n",
    "\t\t\trows = [\n",
    "\t\t\t\t(row.get(primary_key, ''), row['produto'], row['marca'], marca_por_produto[row['produto']])\n",
    "\t\t\t\tfor _, row in inconsistentes.head(5).iterrows()\n",
    "\t\t\t]\n",
    "\t\t\treport += format_section(\"üè∑Ô∏è Inconsist√™ncias produto-marca\", format_table([\"ID\", \"Produto\", \"Marca\", \"Marca esperada\"], rows))\n",
    "\t\t\tif len(inconsistentes) > 5:\n",
    "\t\t\t\treport += f\"\\n*Mostrando 5 de {len(inconsistentes)} inconsist√™ncias...*\\n\"\n",
    "\n",
    "\treport += \"\\n---\\nRelat√≥rio gerado automaticamente\\n\"\n",
    "\n",
    "\treturn report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb87fd",
   "metadata": {},
   "source": [
    "# MegaSuperVendas - Limpeza e normalizar os dados do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c3e10d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo: ../dataframe/vendas_modificado.csv\n",
      "DataFrame criado com sucesso.\n",
      "Normalizando a coluna 'status'...\n",
      "Removendo caracteres especiais da coluna 'produto'...\n",
      "Normalizando os nomes dos produtos...\n",
      "Normalizando os valores monet√°rios...\n",
      "Corrigindo a capitaliza√ß√£o dos campos de texto...\n",
      "Preenchendo valores ausentes na coluna 'vendedor'...\n",
      "Normalizando os valores monet√°rios na coluna 'valor'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_17908\\4121717721.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(['produto', 'marca'], group_keys=False).apply(remove_outliers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preenchendo valores ausentes nas colunas 'valor' e 'frete'...\n",
      "Normalizando as colunas 'frete' e 'total'...\n",
      "Normalizando as colunas de data e hora...\n",
      "Corrigindo o formato dos CEPs...\n",
      "Calculando o total...\n",
      "Removendo linhas onde 'vendedor' √© NaN...\n",
      "Calculando a moda do frete por cidade...\n",
      "Preenchendo os valores de frete ausentes com base no CEP...\n",
      "Corrigindo os formatos das colunas...\n",
      "Removendo dados faltantes...\n",
      "Corrigindo valores inconsistentes...\n",
      "Corrigindo inconsist√™ncias entre produto e marca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_17908\\2828738096.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  marca_mais_comum = df_validos.groupby('produto')['marca'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else \"Desconhecido\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removendo dados duplicados...\n",
      "Salvando o DataFrame limpo...\n",
      "DataFrame salvo com sucesso em ../result/compras_normalizadas.csv\n",
      "Gerando o relat√≥rio de altera√ß√µes...\n",
      "# Relat√≥rio de Altera√ß√µes nos Dados\n",
      "**Data de gera√ß√£o:** 21/04/2025 17:28\n",
      "\n",
      "### üìä Estat√≠sticas B√°sicas\n",
      "- Registros antes: 368752\n",
      "- Registros depois: 353417\n",
      "### ‚úèÔ∏è Altera√ß√µes nos Valores\n",
      "\n",
      "### üîÑ Mudan√ßas em Valores Nulos\n",
      "| Coluna | Nulos removidos |\n",
      "| ------ | --------------- |\n",
      "| FRETE | 7371 |\n",
      "| TOTAL | 3685 |\n",
      "| VENDEDOR | 3680 |\n",
      "### ‚ö†Ô∏è Poss√≠veis Inconsist√™ncias\n",
      "\n",
      "\n",
      "---\n",
      "Relat√≥rio gerado automaticamente\n",
      "\n",
      "Relat√≥rio salvo em 'relatorio_alteracoes.md'\n"
     ]
    }
   ],
   "source": [
    "# L√™ o arquivo CSV e cria um DataFrame\n",
    "\n",
    "df = readCsv('../dataframe/vendas_modificado.csv')\n",
    "df_mod = None\n",
    "# Verifica se o DataFrame foi criado\n",
    "if df is not None:\n",
    "    print(\"DataFrame criado com sucesso.\")\n",
    "    df_mod = df.copy()\n",
    "else:\n",
    "    print(\"Erro ao criar o DataFrame. Verifique o arquivo CSV.\")\n",
    "\n",
    "# Aplicando a fun√ß√£o ao DataFrame\n",
    "df_mod = clean_whitespace(df_mod)\n",
    "\n",
    "# Normaliza a coluna 'status' do DataFrame\n",
    "if df_mod is not None and 'status' in df_mod.columns:\n",
    "    print(\"Normalizando a coluna 'status'...\")\n",
    "    df_mod = normalize_status(df_mod)\n",
    "\n",
    "# Chamando a fun√ß√£o para remover caracteres especiais das colunas desejadas\n",
    "if df_mod is not None and 'produto' in df_mod.columns:\n",
    "    print(\"Removendo caracteres especiais da coluna 'produto'...\")\n",
    "    df_mod = remove_special_characters(df_mod, ['produto'])\n",
    "\n",
    "# Aplicando a fun√ß√£o para normalizar os nomes dos produtos\n",
    "if df_mod is not None and 'produto' in df_mod.columns:\n",
    "    print(\"Normalizando os nomes dos produtos...\")\n",
    "    df_mod = compare_and_normalize_products(df_mod, column='produto')\n",
    "\n",
    "# Normaliza os valores monet√°rios\n",
    "if df_mod is not None and 'valor' in df_mod.columns:\n",
    "    print(\"Normalizando os valores monet√°rios...\")\n",
    "    df_mod = normalize_monetary_values(df_mod.copy(), \"valor\")\n",
    "\n",
    "# Chamando a fun√ß√£o para corrigir a capitaliza√ß√£o\n",
    "if df_mod is not None:\n",
    "    print(\"Corrigindo a capitaliza√ß√£o dos campos de texto...\")\n",
    "    df_mod = correct_text_capitalization(df_mod)\n",
    "\n",
    "# Preenche valores ausentes na coluna 'vendedor'\n",
    "if df_mod is not None and 'vendedor' in df_mod.columns:\n",
    "    print(\"Preenchendo valores ausentes na coluna 'vendedor'...\")\n",
    "    df_mod = fill_missing_vendedor(df_mod)\n",
    "\n",
    "# Limpa e padroniza a coluna de valor\n",
    "if df_mod is not None and 'valor' in df_mod.columns:\n",
    "    print(\"Normalizando os valores monet√°rios na coluna 'valor'...\")\n",
    "    df_mod = normalize_price_data(df_mod)\n",
    "\n",
    "# Chamando a fun√ß√£o para preencher valores ausentes\n",
    "if df_mod is not None and 'valor' in df_mod.columns and 'frete' in df_mod.columns:\n",
    "    print(\"Preenchendo valores ausentes nas colunas 'valor' e 'frete'...\")\n",
    "    df_mod = fill_missing_values(df_mod, ['valor', 'frete'])\n",
    "\n",
    "# Chamando a fun√ß√£o para normalizar as colunas 'frete' e 'total'\n",
    "if df_mod is not None and 'frete' in df_mod.columns and 'total' in df_mod.columns:\n",
    "    print(\"Normalizando as colunas 'frete' e 'total'...\")\n",
    "    df_mod = normalize_numeric_columns(df_mod, ['valor', 'quantidade', 'frete', 'total'])\n",
    "\n",
    "\n",
    "# Chamando a fun√ß√£o para normalizar as colunas de data e hora\n",
    "if df_mod is not None and 'data' in df_mod.columns and 'hora' in df_mod.columns:\n",
    "    print(\"Normalizando as colunas de data e hora...\")\n",
    "    df_mod = normalize_datetime_columns(df_mod)\n",
    "\n",
    "# Chamando a fun√ß√£o para corrigir os CEPs\n",
    "if df_mod is not None and 'cep' in df_mod.columns:\n",
    "    print(\"Corrigindo o formato dos CEPs...\")\n",
    "    df_mod = correct_cep_format(df_mod)\n",
    "\n",
    "# Chamando para calcular o total\n",
    "if df_mod is not None and 'valor' in df_mod.columns and 'quantidade' in df_mod.columns and 'frete' in df_mod.columns:\n",
    "    print(\"Calculando o total...\")\n",
    "    df_mod = calculate_total(df_mod)\n",
    "\n",
    "# Removendo linhas onde 'vendedor' √© NaN\n",
    "if df_mod is not None and 'vendedor' in df_mod.columns:\n",
    "    print(\"Removendo linhas onde 'vendedor' √© NaN...\")\n",
    "    df_mod = df_mod.dropna(subset=['vendedor'])\n",
    "\n",
    "# Calculando a moda do frete por cidade\n",
    "if df_mod is not None and 'cidade' in df_mod.columns and 'frete' in df_mod.columns:\n",
    "    print(\"Calculando a moda do frete por cidade...\")\n",
    "    moda_cep = df_mod.groupby('cidade')['frete'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else None)\n",
    "\n",
    "# Aplicando a fun√ß√£o ao DataFrame\n",
    "if df_mod is not None and 'frete' in df_mod.columns:\n",
    "    print(\"Preenchendo os valores de frete ausentes com base no CEP...\")\n",
    "    df_mod = fill_frete_by_cep(df_mod, moda_cep)\n",
    "    df_mod['frete'] = df_mod['frete'].round(2)\n",
    "\n",
    "# Corrigindo os formatos das colunas\n",
    "if df_mod is not None:\n",
    "    print(\"Corrigindo os formatos das colunas...\")\n",
    "    df_mod = correct_column_formats(df_mod)\n",
    "    print(\"Removendo dados faltantes...\")\n",
    "    df_mod = handle_missing_values(df_mod)\n",
    "    print(\"Corrigindo valores inconsistentes...\")\n",
    "    df_mod = handle_inconsistent_values(df_mod)\n",
    "    print(\"Corrigindo inconsist√™ncias entre produto e marca...\")\n",
    "    df_mod = resolve_product_brand_discrepancies(df_mod)\n",
    "\n",
    "# Remover dados duplicados\n",
    "if df_mod is not None:\n",
    "    print(\"Removendo dados duplicados...\")\n",
    "    df_mod = df_mod.drop_duplicates()\n",
    "\n",
    "    \n",
    "# Transforma o header (nomes das colunas) em mai√∫sculas\n",
    "df.columns = df.columns.str.upper()\n",
    "df_mod.columns = df_mod.columns.str.upper()\n",
    "\n",
    "# Chamando a fun√ß√£o para salvar o DataFrame limpo\n",
    "if df_mod is not None:\n",
    "    print(\"Salvando o DataFrame limpo...\")\n",
    "    save_cleaned_dataframe(df_mod, '../result/compras_normalizadas.csv')\n",
    "\n",
    "# Gerando o relat√≥rio de altera√ß√µes\n",
    "if df is not None and df_mod is not None:\n",
    "    print(\"Gerando o relat√≥rio de altera√ß√µes...\")\n",
    "    relatorio = generate_dataframe_change_report(df, df_mod)\n",
    "    print(relatorio)\n",
    "    # Salvando o relat√≥rio em um arquivo Markdown\n",
    "    with open('../result/relatorio_alteracoes.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(relatorio)\n",
    "        print(\"Relat√≥rio salvo em 'relatorio_alteracoes.md'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
